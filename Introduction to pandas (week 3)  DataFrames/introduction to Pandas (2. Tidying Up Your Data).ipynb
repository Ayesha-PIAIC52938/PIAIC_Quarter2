{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daec429b",
   "metadata": {},
   "source": [
    "# <div class=\"alert alert-success\" >(2) Tidying Up Your Data\n",
    "    \n",
    "Data analysis typically flows in a processing pipeline that starts with retrieving data from one or more sources. Upon receipt of this data, it is often the case that it can be in a raw form and can be difficult to use for data analysis. This can be for a multitude of reasons such as data is not recorded, it is lost, or it is just in a different format than what you require. \n",
    "    \n",
    "Therefore, one of the most common things you will do with pandas involves tidying your data, which is the process of preparing raw data for analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956dca6c",
   "metadata": {},
   "source": [
    "    \n",
    "## <div class= \"alert alert-info\"> What is tidying your data?\n",
    "    \n",
    "<div class= \"alert alert-success\">\n",
    "    \n",
    "Tidy data is a term that was created in what many refer to as a famous data science paper, \"Tidy Data\" by Hadley Wickham, which I highly recommend that you read and it can be downloaded at http://vita.had.co.nz/papers/tidy-data.pdf. The paper covers many details of the process that he calls tidying data, with the result of the process being that you now have tidy data; data that is ready for analysis.\n",
    "    \n",
    "We'll introduce and briefly demonstrate many of the capabilities of pandas. A  brief summary of the reasons why you need\n",
    "to tidy data and what are the characteristics of tidy data, so that you know you have completed the task and are ready to move on to analysis. Tidying of data is required for many reasons including these:\n",
    "    \n",
    "- The names of the variables are different from what you require\n",
    "    \n",
    "- There is missing data\n",
    "    \n",
    "- Values are not in the units that you require\n",
    "    \n",
    "- The period of sampling of records is not what you need\n",
    "    \n",
    "- Variables are categorical and you need quantitative values\n",
    "    \n",
    "- There is noise in the data\n",
    "    \n",
    "- Information is of an incorrect type\n",
    "    \n",
    "- Data is organized around incorrect axes\n",
    "    \n",
    "- Data is at the wrong level of normalization\n",
    "    \n",
    "- Data is duplicated\n",
    "    \n",
    "There are several characteristics of data that can be considered good, tidy, and ready for analysis, which are as follows:\n",
    "    \n",
    "- Each variable is in one column\n",
    "    \n",
    "- Each observation of the variable is in a different row\n",
    "    \n",
    "- There should be one table for each kind of variable\n",
    "    \n",
    "- If multiple tables, they should be relatable\n",
    "    \n",
    "- Qualitative and categorical variables have mappings to values useful for analysis\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a0c21",
   "metadata": {},
   "source": [
    "<div class= \"alert alert-success\">\n",
    "    \n",
    "### <div class= \"alert alert-warning\">Setting up the IPython notebook\n",
    "    \n",
    "To utilize the examples in this chapter, we will need to include the following imports and settings:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73be2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas, numpy and datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Set some pandas options for controlling output\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096b541b",
   "metadata": {},
   "source": [
    "## <div class= \"alert alert-info\"> Working with missing data\n",
    "    \n",
    "<div class= \"alert alert-success\">\n",
    "    \n",
    "Data is \"missing\" in pandas when it has a value of NaN (also seen as np.nanâ€”the form from NumPy). The NaN value represents that in a particular Series that there is not a value specified for the particular index label. In pandas, there are a number of reasons why a value can be NaN:\n",
    "    \n",
    "- A join of two sets of data does not have matched values\n",
    "    \n",
    "- Data that you retrieved from an external source is incomplete\n",
    "    \n",
    "- The NaN value is not known at a given point in time and will be filled in later\n",
    "    \n",
    "- There is a data collection error retrieving a value, but the event must still be recorded in the index \n",
    "    \n",
    "- Reindexing of data has resulted in an index that does not have a value\n",
    "    \n",
    "- The shape of data has changed and there are now additional rows or columns, which at the time of reshaping could not be determined\n",
    "    \n",
    "To demonstrate handling missing data, we will use the following DataFrame object, which exhibits various patterns of missing data:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2dd1d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   c1  c2  c3\n",
       "a   0   1   2\n",
       "b   3   4   5\n",
       "c   6   7   8\n",
       "d   9  10  11\n",
       "e  12  13  14"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame with 5 rows and 3 columns\n",
    "df = pd.DataFrame(np.arange(0, 15).reshape(5, 3),index=['a', 'b', 'c', 'd', 'e'],columns=['c1', 'c2', 'c3'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d697da2d",
   "metadata": {},
   "source": [
    "There is no missing data at this point, so let's add some:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa7bfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   NaN   NaN   NaN   NaN NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['c4'] = np.nan                   # adding column c4 with NaN values\n",
    "df.loc['f'] = np.arange(15, 19)     # adding row 'f' with 15 through 18\n",
    "df.loc['g'] = np.nan                # adding row 'g' will all NaN\n",
    "df['c5'] = np.nan                   # adding column 'C5' with NaN's\n",
    "df['c4']['a'] = 20                  # adding c4 and change value in col 'c4' row 'a'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8927f77",
   "metadata": {},
   "source": [
    "This DataFrame object exhibits the following characteristics that will support most of the examples that follow in this section:\n",
    "\n",
    "- One row consisting only of NaN values\n",
    "\n",
    "- One column is consisiting only of NaN values\n",
    "\n",
    "- Several rows and columns consisting of both numeric values and NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bcbb57",
   "metadata": {},
   "source": [
    "<div class= \"alert alert-success\">\n",
    "    \n",
    "### <div class= \"alert alert-warning\"> Determining NaN values in Series and DataFrame objects\n",
    "\n",
    "The NaN values in a DataFrame object can be identified using the <span style=\"color:red\">.isnull()</span> method.\n",
    "Any True value means that the item is a NaN value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c15bf825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      c1     c2     c3     c4    c5\n",
       "a  False  False  False  False  True\n",
       "b  False  False  False   True  True\n",
       "c  False  False  False   True  True\n",
       "d  False  False  False   True  True\n",
       "e  False  False  False   True  True\n",
       "f  False  False  False  False  True\n",
       "g   True   True   True   True  True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()         # which items are NaN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961bd110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1    1\n",
       "c2    1\n",
       "c3    1\n",
       "c4    5\n",
       "c5    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()               # count the number of NaN values in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb86c0b0",
   "metadata": {},
   "source": [
    "Applying .sum() to the resulting series gives the total number of NaN values in the original DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcc41f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()     # total count of NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa413d0",
   "metadata": {},
   "source": [
    "Another way to determine this is to use the <span style=\"color:red\">.count()</span> method of a Series object and DataFrame. <mark>For a Series method, this method will return the number of non-NaN values. For a DataFrame object, it will count the number of non-NaN values in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "026e3154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1    6\n",
       "c2    6\n",
       "c3    6\n",
       "c4    2\n",
       "c5    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()      # number of non-NaN values in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4013b6ac",
   "metadata": {},
   "source": [
    "This then needs to be flipped around to sum the number of NaN values, which can be calculated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd6497d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df) - df.count()).sum()         # and this counts the number of NaN values too"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38961afb",
   "metadata": {},
   "source": [
    "We can also determine whether an item is not NaN using the <span style=\"color:red\">.notnull()</span> method, which returns True if the value is not a NaN value, otherwise it returns False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd68ab78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      c1     c2     c3     c4     c5\n",
       "a   True   True   True   True  False\n",
       "b   True   True   True  False  False\n",
       "c   True   True   True  False  False\n",
       "d   True   True   True  False  False\n",
       "e   True   True   True  False  False\n",
       "f   True   True   True   True  False\n",
       "g  False  False  False  False  False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.notnull()             # which items are not null?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d538e70",
   "metadata": {},
   "source": [
    "<div class= \"alert alert-success\">\n",
    "    \n",
    "### <div class= \"alert alert-warning\">Selecting out or dropping missing data\n",
    "    \n",
    "One technique of handling missing data, is to simply remove it from your dataset. A scenario for this would be where data is sampled at regular intervals, but devices are offline and do not receive a reading, but you only need the actual periodic values.\n",
    "    \n",
    " The pandas library makes this possible using several techniques; one is through Boolean selection using the results of .isnull() and .notnull() to retrieve the values that are NaN or not NaN out of a Series object. To demonstrate, the following example selects all non-NaN values from the c4 column of DataFrame:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "436525a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "f    18.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.c4[df.c4.notnull()]    # select the non-NaN items in column c4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc31ec3",
   "metadata": {},
   "source": [
    "pandas also provides a convenience function <span style=\"color:red\">.dropna()</span>, which will drop the items in a Series where the value is NaN, involving less typing than the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0d82344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "f    18.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.c4.dropna()     # .dropna will also return non NaN values. This gets all non NaN items in column c4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858ac99b",
   "metadata": {},
   "source": [
    "Note that .dropna() has actually returned a copy of DataFrame without the rows. The original DataFrame is not changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d7b67a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.c4   # dropna returns a copy with the values dropped, the source DataFrame / column is not changed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbd1902",
   "metadata": {},
   "source": [
    "When applied to a DataFrame object, .dropna() will drop all rows from a DataFrame object that have at least one NaN value. The following code demonstrates this in action, and since each row has at least one NaN value, there are no rows in the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88d30a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [c1, c2, c3, c4, c5]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()  # on a DataFrame this will drop entire rows where there is at least one NaN in this case, that is all rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb582d2",
   "metadata": {},
   "source": [
    "If you want to only drop rows where all values are NaN, you can use the<span style=\"color:green\"> <b>how = ' all '</b></span> parameter. The following code only drops the g row since it has all NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6522cb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(how = 'all')      # using how='all', only rows that have all values as NaN will be dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd1dd9",
   "metadata": {},
   "source": [
    "This can also be applied to the columns instead of the rows, by changing the axis parameter to axis=1. The following code drops the c5 column as it is the only one with all NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec6178fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4\n",
       "a   0.0   1.0   2.0  20.0\n",
       "b   3.0   4.0   5.0   NaN\n",
       "c   6.0   7.0   8.0   NaN\n",
       "d   9.0  10.0  11.0   NaN\n",
       "e  12.0  13.0  14.0   NaN\n",
       "f  15.0  16.0  17.0  18.0\n",
       "g   NaN   NaN   NaN   NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(how='all', axis=1) # say goodbye to c5  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b93735",
   "metadata": {},
   "source": [
    "We can also examine this process using a slightly different DataFrame object that has columns c1 and c3 with all values that are not NaN. In this case, all columns except c1 and c3 will be dropped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b9000ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [a, b, c, d, e, f, g]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2.dropna(how='any', axis=1)   # now drop columns with any NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69ab020",
   "metadata": {},
   "source": [
    "The .dropna() methods also has a parameter, <span style=\"color:green\"> <b>thresh</b></span>, which when given an integer\n",
    "value specifies the minimum number of NaN values that must exist before the drop is performed. The following code drops all columns with at least five NaN values; these are the c4 and c5 columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f8a2438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3\n",
       "a   0.0   1.0   2.0\n",
       "b   3.0   4.0   5.0\n",
       "c   6.0   7.0   8.0\n",
       "d   9.0  10.0  11.0\n",
       "e  12.0  13.0  14.0\n",
       "f  15.0  16.0  17.0\n",
       "g   NaN   NaN   NaN"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(thresh=5, axis=1)        # only drop columns with at least 5 NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2548cae",
   "metadata": {},
   "source": [
    "<mark><b>Note that the .dropna() method (and the Boolean selection) returns a copy of the DataFrame object, and the data is dropped from that copy. If you want to drop the data in the actual DataFrame, use the inplace=True parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2946eafc",
   "metadata": {},
   "source": [
    "<div class= \"alert alert-success\">\n",
    "    \n",
    "### <div class= \"alert alert-warning\">How pandas handles NaN values in mathematical operations\n",
    "    \n",
    "The NaN values are handled differently in pandas than in NumPy. This is demonstrated using the following example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "921f1ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, 2.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, np.nan, 3])      # create a NumPy array with one NaN value\n",
    "s = pd.Series(a)                     # create a Series from the array\n",
    "a.mean(), s.mean()                   # the mean of each is different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d7a9d",
   "metadata": {},
   "source": [
    "<mark>Note that the mean of the preceding series was calculated as (1+2+3)/3 = 2, not (1+2+3)/4, or (1+2+0+4)/4. This verifies that NaN is totally ignored and not even counted as an item in the Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c2b551",
   "metadata": {},
   "source": [
    " NumPy functions, when encountering a NaN value, will return NaN. pandas functions  will typically ignore the NaN values and continue processing the function as though the values were not part of the Series object.More specifically, the way that pandas handles NaN values is as follows:\n",
    " \n",
    "- Summing of data treats NaN as 0\n",
    "\n",
    "- If all values are NaN, the result is NaN\n",
    "\n",
    "- Methods like .cumsum() and .cumprod() ignore NaN values, but preserve them in the resulting arrays\n",
    "\n",
    "The following code demonstrates all of these concepts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f97bc982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df.c4         # demonstrate sum, mean and cumsum handling of NaN, we get one column \n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81d464db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.sum()           # NaN values treated as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c1ffe3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.mean()         # NaN also treated as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0272fb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    38.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "s.cumsum()      # NaN as 0 in the cumsum, but NaN values preserved in result Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1b4cf4",
   "metadata": {},
   "source": [
    "When using traditional mathematical operators, NaN is propagated through to the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d895757f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    21.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    19.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.c4 + 1   # in arithmetic, a NaN value will result in NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d693df4",
   "metadata": {},
   "source": [
    "<div class= \"alert alert-success\">\n",
    "    \n",
    "### <div class= \"alert alert-warning\">Filling in missing data\n",
    "    \n",
    "If you prefer to replace the NaN values with a specific value, instead of having them propagated or flat out ignored, you can use the <span style=\"color:red\">.fillna() </span>method. The following code fills the NaN values with 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f4d4c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4   c5\n",
       "a   0.0   1.0   2.0  20.0  0.0\n",
       "b   3.0   4.0   5.0   0.0  0.0\n",
       "c   6.0   7.0   8.0   0.0  0.0\n",
       "d   9.0  10.0  11.0   0.0  0.0\n",
       "e  12.0  13.0  14.0   0.0  0.0\n",
       "f  15.0  16.0  17.0  18.0  0.0\n",
       "g   0.0   0.0   0.0   0.0  0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled = df.fillna(0)       # return a new DataFrame with NaN values filled with 0\n",
    "filled "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cece3e33",
   "metadata": {},
   "source": [
    "Be aware that this causes differences in the resulting values. As an example, the following code shows the result of applying the .mean() method to the DataFrame object with the NaN values, as compared to the DataFrame that has its NaN values\n",
    "filled with 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18c6304a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1     7.5\n",
       "c2     8.5\n",
       "c3     9.5\n",
       "c4    19.0\n",
       "c5     NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()           # NaNs don't count as an item in calculating the means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d726dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1    6.428571\n",
       "c2    7.285714\n",
       "c3    8.142857\n",
       "c4    5.428571\n",
       "c5    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled.mean()    # having replaced NaN with 0 can make operations such as mean have different results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa182f9",
   "metadata": {},
   "source": [
    "It is also possible to limit the number of times that the data will be filled using the limit parameter. Each time the NaN values are identified, pandas will fill the NaN values with the previous value up to the limit times in each group of NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2373e9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4   c5\n",
       "a   0.0   1.0   2.0  20.0  0.0\n",
       "b   3.0   4.0   5.0   0.0  0.0\n",
       "c   6.0   7.0   8.0   0.0  NaN\n",
       "d   9.0  10.0  11.0   NaN  NaN\n",
       "e  12.0  13.0  14.0   NaN  NaN\n",
       "f  15.0  16.0  17.0  18.0  NaN\n",
       "g   0.0   0.0   0.0   NaN  NaN"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(0, limit=2)       # only fills the first two NaN values in each column with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9077abe",
   "metadata": {},
   "source": [
    "<div class= \"alert alert-danger\">\n",
    "    \n",
    "### <div class= \"alert alert-warning\">Forward and backward filling of missing values\n",
    "    \n",
    "Gaps in data can be filled by propagating non-NaN values forward or backward along a Series. To demonstrate this, the following example will \"fill forward\" the c4 column of DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e583b4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b    20.0\n",
       "c    20.0\n",
       "d    20.0\n",
       "e    20.0\n",
       "f    18.0\n",
       "g    18.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.c4.fillna(method=\"ffill\")   # extract the c4 column and fill NaNs forward (i.e fill NaN with last non NaN value encountered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f55a99e",
   "metadata": {},
   "source": [
    "#### When working with time series data, this technique of filling is often referred to as the \"last known value\".\n",
    "\n",
    "The direction of the fill can be reversed using method='bfill':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57bc8171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b    18.0\n",
       "c    18.0\n",
       "d    18.0\n",
       "e    18.0\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.c4.fillna(method=\"bfill\")        # perform a backwards fill(i.e fill NaN with next not NaN value encountered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0453f4a4",
   "metadata": {},
   "source": [
    "To save a little typing, pandas also has global level functions pd.ffill() and pd.bfill(), which are equivalent to  fillna(method=\"ffill\") and .fillna(method=\"bfill\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd392f7",
   "metadata": {},
   "source": [
    "<div class= \"alert alert-danger\">\n",
    "    \n",
    "### <div class= \"alert alert-warning\">Filling using index labels\n",
    "    \n",
    "Data can be filled using the labels of a Series or keys of a Python dictionary. This\n",
    "allows you to specify different fill values for different elements based upon the value\n",
    "of the index label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb695ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    100\n",
       "e    101\n",
       "g    102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_values = pd.Series([100, 101, 102], index=['a', 'e', 'g']) # new series to fill NaN values where the index label matches\n",
    "fill_values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aec64cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     20.0\n",
       "b      NaN\n",
       "c      NaN\n",
       "d      NaN\n",
       "e    101.0\n",
       "f     18.0\n",
       "g    102.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.c4.fillna(fill_values)   # using c4, fill using fill_values a, e and g will be filled with matching values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e270de4",
   "metadata": {},
   "source": [
    "Only values of NaN will be filled. Notice that the values with label a are not changed. Another common scenario, is to fill all the NaN values in a column with the mean of the column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3377aad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0  19.0 NaN\n",
       "c   6.0   7.0   8.0  19.0 NaN\n",
       "d   9.0  10.0  11.0  19.0 NaN\n",
       "e  12.0  13.0  14.0  19.0 NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   7.5   8.5   9.5  19.0 NaN"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(df.mean())           # fill NaN values in each column with the mean of the values in that column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e423f64",
   "metadata": {},
   "source": [
    "<div class= \"alert alert-danger\">\n",
    "    \n",
    "### <div class= \"alert alert-warning\">Interpolation of missing values\n",
    "    \n",
    "Both DataFrame and Series have an <span style=\"color:red\">.interpolate()</span> method that will, by default, perform a linear interpolation of missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02971337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.00\n",
       "1    1.25\n",
       "2    1.50\n",
       "3    1.75\n",
       "4    2.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, np.nan, np.nan, np.nan, 2])\n",
    "s.interpolate()    # linear interpolate the NaN values from 1 through 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eba451",
   "metadata": {},
   "source": [
    "The value of the interpolation is calculated by taking the first value before and after any sequence of NaN values and then incrementally adding that value from the start and substituting NaN values. <mark><b>In this case, 2.0 and 1.0 are the surrounding values, resulting in (2.0 â€“ 1.0)/(5-1) = 0.25, which is then added incrementally through all the NaN values.</b></mark>\n",
    "\n",
    "The interpolation method also has the ability to specify a specific method of interpolation. One of the common methods is to use time-based interpolation. Consider the following Series of dates and values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4ada3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-01    1.0\n",
       "2014-02-01    NaN\n",
       "2014-04-01    2.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a time series, but missing one date in the Series\n",
    "ts = pd.Series([1, np.nan, 2],\n",
    "               index=[datetime.datetime(2014, 1, 1),datetime.datetime(2014, 2, 1),datetime.datetime(2014, 4, 1)])\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9506094a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-01    1.0\n",
       "2014-02-01    1.5\n",
       "2014-04-01    2.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.interpolate()    # linear interpolate based on the number of items in the Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9c4fd1",
   "metadata": {},
   "source": [
    " The value for 2014-02-01 is calculated as 1.0 + (2.0-1.0)/2 = 1.5, since there is one NaN value between the values 2.0 and 1.0.\n",
    " \n",
    "The important thing to note is that the series is missing an entry for 2014-03-01. If we were expecting to interpolate daily values, there would be two values calculated, one for 2014-02-01 and another for 2014-03-01, resulting in one more value in the\n",
    "numerator of the interpolation. This can be corrected by specifying the method of interpolation as \"time\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b184fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-01    1.000000\n",
       "2014-02-01    1.344444\n",
       "2014-04-01    2.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.interpolate(method=\"time\")  # this accounts for the fact that we don't have an entry for 2014-03-01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d2606",
   "metadata": {},
   "source": [
    "This is the correct interpolation for 2014-02-01 based upon dates. Also note that the index label and value for 2014-03-01 is not added to the Series, it is just factored into the interpolation. Interpolation can also be specified to calculate values relative to the index values when using numeric index labels. To demonstrate this, we will use the following Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09bbbabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       NaN\n",
       "10    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([0, np.nan, 100], index=[0, 1, 10])   # a Series to demonstrate index label based interpolation\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d356b85f",
   "metadata": {},
   "source": [
    "If we perform a linear interpolation, we get the following value for label 1, which is correct for a linear interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6936d809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1      50.0\n",
       "10    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.interpolate() # linear interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a28e3",
   "metadata": {},
   "source": [
    "However, what if we want to interpolate the value to be relative to the index value? To do this, we can use method=\"values\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15e081cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1      10.0\n",
       "10    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.interpolate(method=\"values\")  # interpolate based upon the values in the index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9df70a",
   "metadata": {},
   "source": [
    "Now, the value calculated for NaN is interpolated using relative positioning based upon the labels in the index. The NaN value has a label of 1, which is one tenth of the way between 0 and 10, so the interpolated value will be 0 + (100-0)/10, or 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7668ea5",
   "metadata": {},
   "source": [
    "## <div class= \"alert alert-info\"> Handling duplicate data\n",
    "<div class= \"alert alert-success\">\n",
    "The data in your sample can often contain duplicate rows. This is just a reality of dealing with data collected automatically, or even a situation created in manually collecting data. Often, it is considered best to err on the side of having duplicates\n",
    "instead of missing data, especially if the data can be considered to be <b>idempotent ( relating to or being a mathematical quantity which when applied to itself under a given binary operation, say multiplication, equals itself. also : relating to or being an operation under which a mathematical quantity is idempotent)</b>. However, duplicate data can increase the size of the dataset, and if it is not idempotent, then it would not be appropriate to process the duplicates. \n",
    "    \n",
    "To facilitate finding duplicate data, pandas provides a <span style=\"color:red\">.duplicates()</span> method that returns a Boolean Series where each entry represents whether or not the row is a duplicate. A True value represents that the specific row has appeared earlier in the DataFrame object with all column values being identical. To demonstrate this, the following code creates a DataFrame object with duplicate rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "409d16d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b\n",
       "0  x  1\n",
       "1  x  1\n",
       "2  x  2\n",
       "3  y  3\n",
       "4  y  3\n",
       "5  y  4\n",
       "6  y  4"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'a': ['x'] * 3 + ['y'] * 4,'b': [1, 1, 2, 3, 3, 4, 4]}) # a DataFrame with lots of duplicate data\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb8ca28",
   "metadata": {},
   "source": [
    "A DataFrame object with duplicate rows which were created by the preceding code can be analyzed using .duplicated() method. This method determines that a row is a duplicate if the values in all columns were seen already in a row earlier in the\n",
    "DataFrame object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d3646651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "4     True\n",
       "5    False\n",
       "6     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated()    # reports which rows are duplicates based upon if the data in all columns was seen before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9443cefc",
   "metadata": {},
   "source": [
    "Duplicate rows can be dropped from a DataFrame using the <span style=\"color:red\"> .drop_duplicates()</span>\n",
    "method. This method will return a copy of the DataFrame object with the duplicate rows removed. It is also possible to use the inplace=True parameter to remove the rows without\n",
    "making a copy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7168d8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b\n",
       "0  x  1\n",
       "2  x  2\n",
       "3  y  3\n",
       "5  y  4"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates()      # drop duplicate rows retaining first row of the duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f2a73",
   "metadata": {},
   "source": [
    "Note that there is a ramification to which indexes remain when dropping duplicates. The duplicate records may have different index labels (labels are not taken into account in calculating a duplicate). So, which row is kept can affect the set of labels\n",
    "in the resulting DataFrame object. \n",
    "\n",
    "The default operation is to keep the first row of the duplicates. If you want to keep the last row of duplicates, you can use the <span style=\"color:green\"><b>keep =' first ' </b></span> parameter. The following code demonstrates how the result differs using this parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "69d226b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b\n",
       "0  x  1\n",
       "2  x  2\n",
       "3  y  3\n",
       "5  y  4"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(keep='first')    # drop duplicate rows, only keeping the first instance of any data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "04107741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b\n",
       "1  x  1\n",
       "2  x  2\n",
       "4  y  3\n",
       "6  y  4"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(keep='last')    # drop duplicate rows, only keeping the first instance of any data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa688864",
   "metadata": {},
   "source": [
    " If you want to check for duplicates based on a smaller set of columns, you can specify a list of columns names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee8acc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['c'] = range(7)    # add a column c with values 0..6 this makes .duplicated() report no duplicate rows\n",
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cefb7d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b  c\n",
       "0  x  1  0\n",
       "2  x  2  2\n",
       "3  y  3  3\n",
       "5  y  4  5"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(['a', 'b']) # but if we specify duplicates to be dropped only in columns a & b they will be dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147b19fd",
   "metadata": {},
   "source": [
    "## <div class= \"alert alert-info\"> Transforming Data\n",
    "<div class= \"alert alert-success\">\n",
    "Another part of tidying data involves transforming existing data into another presentation. This may be needed for the following reasons:\n",
    "    \n",
    "- Values are not in the correct units\n",
    "    \n",
    "- Values are qualitative and need to be converted to appropriate numeric values\n",
    "    \n",
    "- There is extraneous data that either wastes memory and processing time, or can affect results simply by being included\n",
    "    \n",
    "To address these situations, we can take one or more of the following actions:\n",
    "    \n",
    "- Map values to other values using a table lookup process\n",
    "    \n",
    "- Explicitly replace certain values with other values (or even another type of data)\n",
    "    \n",
    "- Apply methods to transform the values based on an algorithm\n",
    "    \n",
    "- Simply remove extraneous columns and rows\n",
    "    \n",
    "We have already seen how to delete rows and columns with several techniques, so we will not reiterate those here. We will cover the facilities provided by pandas for mapping, replacing, and applying functions to transform data based upon its content.    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828128a9",
   "metadata": {},
   "source": [
    "<div class= \"alert alert-success\">\n",
    "    \n",
    "### <div class= \"alert alert-warning\"> Mapping\n",
    "    \n",
    "One of the basic tasks in data transformations is mapping of a set of values to another set. pandas provides a generic ability to map values using a lookup table (via a Python dictionary or a pandas Series) using the .map() method. This method\n",
    "performs the mapping by matching the values of the outer Series with the index labels of the inner Series, and returning a new Series with the index labels of the outer Series but the values from the inner Series:\n",
    "In [46]:\n",
    "# create two Series objects to demonstrate mapping\n",
    "x = pd.Series({\"one\": 1, \"two\": 2, \"three\": 3})\n",
    "y = pd.Series({1: \"a\", 2: \"b\", 3: \"c\"})\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "113b8363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one      a\n",
       "two      b\n",
       "three    c\n",
       "dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.Series({\"one\": 1, \"two\": 2, \"three\": 3})  # create two Series objects to demonstrate mapping\n",
    "y = pd.Series({1: \"a\", 2: \"b\", 3: \"c\"})\n",
    "\n",
    "x.map(y) # map values in x to values in y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652453eb",
   "metadata": {},
   "source": [
    "Like with other alignment operations, if pandas does not find a map between the value of the outer Series and an index label of the inner Series, it will fill the value with NaN. To demonstrate this, the following code removes the 3 key from the outer\n",
    "Series, therefore causing the alignment to fail for that record, and the result is that a\n",
    "NaN value is introduced:\n",
    "In [49]:\n",
    "\n",
    "x = pd.Series({\"one\": 1, \"two\": 2, \"three\": 3})  # three in x will not align / map to a value in y\n",
    "y = pd.Series({1: \"a\", 2: \"b\"})\n",
    "x.map(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0b8cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed154f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a091eddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e0c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71e01131",
   "metadata": {},
   "source": [
    "<div class= \"alert alert-success\">\n",
    "    \n",
    "### <div class= \"alert alert-warning\"> Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70500b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47db2b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02da212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8cf42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c007497",
   "metadata": {},
   "source": [
    "<div class= \"alert alert-success\">\n",
    "    \n",
    "### <div class= \"alert alert-warning\"> Applying functions to transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5891d372",
   "metadata": {},
   "source": [
    "### <div class= \"alert alert-danger\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
